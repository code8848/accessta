{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import osmnx as ox\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al=pd.read_excel(\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/#RAW/Data/FullSUPIdentifiedData.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df_al[['stationid', 'Latitude', 'Longitude']]\n",
    "df_all=df_all.drop_duplicates(subset=['stationid'], keep='first')\n",
    "df_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all=gpd.GeoDataFrame(df_all, geometry=gpd.points_from_xy(df_all.Longitude, df_all.Latitude), crs='EPSG:4326')\n",
    "gdf_all.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files= os.listdir('Data/weather/Texas GSOY station data')\n",
    "weather_files=[f for f in files if f.endswith('.csv')]\n",
    "dataset=[]\n",
    "for i in weather_files:\n",
    "    file=pd.read_csv(\"Data/weather/Texas GSOY station data/\"+i)\n",
    "    dataset.append(file)\n",
    "weather_data=pd.concat(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info on all weather stations in texas (thousands..)\n",
    "file=\"Data/weather/Texas GSOY station data/stations_info.txt\"\n",
    "df = pd.read_csv(file, sep='\\s+', header=None, usecols=[0,1,2], names=['stationid', 'Lat', 'Lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data2=weather_data.merge(df, right_on=\"stationid\", left_on=\"STATION\")\n",
    "weather_data3=weather_data2[['stationid','DATE','Lon','Lat','PRCP', 'TAVG','TMAX', 'TMIN', 'AWND']]\n",
    "weather_data3=weather_data3.rename(columns={\"stationid\":\"weather_station\"})\n",
    "weather_data3['DATE']=(weather_data3['DATE'].astype(str).str[:4]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "df_all2=df_all.copy(deep=True)\n",
    "weather_data_unq=weather_data3.drop_duplicates(subset = ['weather_station'], keep='first')\n",
    "#Haversine formula\n",
    "def calc_distance(lon1, lat1, lon2, lat2):\n",
    "    R = 6371  # earth radius in km\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "for i, row in df_all.iterrows():\n",
    "    # calculate the distance between this station and all stations in the second dataset\n",
    "    distances = []\n",
    "    for j, row2 in weather_data_unq.iterrows(): \n",
    "        distance = calc_distance(row['Longitude'], row['Latitude'], row2['Lon'], row2['Lat'])\n",
    "        distances.append((row2['weather_station'], distance, row['stationid']))\n",
    "    # find the STATIONID in the second dataset with the shortest distance\n",
    "    min_distance = min(distances, key=lambda x: x[1])\n",
    "    distances.remove(min_distance)\n",
    "    min_distance2 = min(distances, key=lambda x: x[1])\n",
    "    distances.remove(min_distance2)\n",
    "    min_distance3 = min(distances, key=lambda x: x[1])\n",
    "    distances.remove(min_distance3)\n",
    "    min_distance4 = min(distances, key=lambda x: x[1])\n",
    "\n",
    "    #print(min_distance2)\n",
    "    # assign the STATIONID to the corresponding row in the first dataset\n",
    "    df_all2.loc[i, 'weather_station'] = min_distance[0]\n",
    "    df_all2.loc[i, 'distance(km)'] = min_distance[1]\n",
    "    df_all2.loc[i, 'weather_station2'] = min_distance2[0]\n",
    "    df_all2.loc[i, 'distance(km)2'] = min_distance2[1]\n",
    "    df_all2.loc[i, 'weather_station3'] = min_distance3[0]\n",
    "    df_all2.loc[i, 'distance(km)3'] = min_distance3[1]\n",
    "    df_all2.loc[i, 'weather_station4'] = min_distance4[0]\n",
    "    df_all2.loc[i, 'distance(km)4'] = min_distance4[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2.to_csv(\"Data/Temp/FULL_nearest_weather_stationid_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Selecting stations with > 10KM distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all3=df_all2.copy(deep=True)\n",
    "df_all3.set_index(df_all3.stationid, drop=True, inplace=True)\n",
    "df_all3.loc[(df_all3['distance(km)4']>10), 'weather_station4']=np.nan #only weather_station4 is checked because others were checked manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data4=weather_data3.copy(deep=True)\n",
    "#weather_data4.set_index(weather_data3.weather_station, drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aa=pd.read_excel(\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/#RAW/Data/Temp/FULL_prepared_data_ampm_v7.xlsx\")\n",
    "#df_aa=df_aa[['stationid', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations=df_aa.merge(df_all3, left_on=df_aa.stationid, right_on=df_all3.stationid,)\n",
    "df_stations.rename(columns={'stationid_x':'stationid'}, inplace=True)\n",
    "df_stations.drop(['stationid_y', 'key_0', 'Latitude', 'Longitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining weather data and stations based on year\n",
    "a=df_stations.merge(weather_data4, right_on=['weather_station', 'DATE'], left_on=['weather_station', 'year'], how='left')\n",
    "b=a.groupby(['stationid','year'],as_index=False )[('DATE',\t'PRCP',\t'TAVG',\t'TMAX',\t'TMIN',\t'AWND')].first()\n",
    "ws1 = b.rename(columns={c: c+'_1' for c in b.columns if c not in ['stationid', 'year']})\n",
    "\n",
    "a=df_stations.merge(weather_data4, right_on=['weather_station', 'DATE'], left_on=['weather_station2', 'year'], how='left')\n",
    "b=a.groupby(['stationid','year'],as_index=False )[('DATE',\t'PRCP',\t'TAVG',\t'TMAX',\t'TMIN',\t'AWND')].first()\n",
    "ws2 = b.rename(columns={c: c+'_2' for c in b.columns if c not in ['stationid', 'year']})\n",
    "\n",
    "a=df_stations.merge(weather_data4, right_on=['weather_station', 'DATE'], left_on=['weather_station3', 'year'], how='left')\n",
    "b=a.groupby(['stationid','year'],as_index=False )[('DATE',\t'PRCP',\t'TAVG',\t'TMAX',\t'TMIN',\t'AWND')].first()\n",
    "ws3 = b.rename(columns={c: c+'_3' for c in b.columns if c not in ['stationid', 'year']})\n",
    "\n",
    "a=df_stations.merge(weather_data4, right_on=['weather_station', 'DATE'], left_on=['weather_station4', 'year'], how='left')\n",
    "b=a.groupby(['stationid','year'],as_index=False )[('DATE',\t'PRCP',\t'TAVG',\t'TMAX',\t'TMIN',\t'AWND')].first()\n",
    "ws4 = b.rename(columns={c: c+'_4' for c in b.columns if c not in ['stationid', 'year']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting missing values from the next nearest weather station\n",
    "#PRCP\n",
    "ws1.loc[ws1.PRCP_1.isna(), 'PRCP_1']= ws2.loc[ws1.PRCP_1.isna(), 'PRCP_2']\t\n",
    "ws1.loc[ws1.PRCP_1.isna(), 'PRCP_1']= ws3.loc[ws1.PRCP_1.isna(), 'PRCP_3']\t\n",
    "ws1.loc[ws1.PRCP_1.isna(), 'PRCP_1']= ws4.loc[ws1.PRCP_1.isna(), 'PRCP_4']\t\n",
    "#TAVG\n",
    "ws1.loc[ws1.TAVG_1.isna(), 'TAVG_1']= ws2.loc[ws1.TAVG_1.isna(), 'TAVG_2']\t\n",
    "ws1.loc[ws1.TAVG_1.isna(), 'TAVG_1']= ws3.loc[ws1.TAVG_1.isna(), 'TAVG_3']\t\n",
    "ws1.loc[ws1.TAVG_1.isna(), 'TAVG_1']= ws4.loc[ws1.TAVG_1.isna(), 'TAVG_4']\t\n",
    "#TMAX\n",
    "ws1.loc[ws1.TMAX_1.isna(), 'TMAX_1']= ws2.loc[ws1.TMAX_1.isna(), 'TMAX_2']\t\n",
    "ws1.loc[ws1.TMAX_1.isna(), 'TMAX_1']= ws3.loc[ws1.TMAX_1.isna(), 'TMAX_3']\t\n",
    "ws1.loc[ws1.TMAX_1.isna(), 'TMAX_1']= ws4.loc[ws1.TMAX_1.isna(), 'TMAX_4']\t\n",
    "#TMIN\n",
    "ws1.loc[ws1.TMIN_1.isna(), 'TMIN_1']= ws2.loc[ws1.TMIN_1.isna(), 'TMIN_2']\t\n",
    "ws1.loc[ws1.TMIN_1.isna(), 'TMIN_1']= ws3.loc[ws1.TMIN_1.isna(), 'TMIN_3']\t\n",
    "ws1.loc[ws1.TMIN_1.isna(), 'TMIN_1']= ws4.loc[ws1.TMIN_1.isna(), 'TMIN_4']\t\n",
    "#AWND\n",
    "ws1.loc[ws1.AWND_1.isna(), 'AWND_1']= ws2.loc[ws1.AWND_1.isna(), 'AWND_2']\t\n",
    "ws1.loc[ws1.AWND_1.isna(), 'AWND_1']= ws3.loc[ws1.AWND_1.isna(), 'AWND_3']\t\n",
    "ws1.loc[ws1.AWND_1.isna(), 'AWND_1']= ws4.loc[ws1.AWND_1.isna(), 'AWND_4']\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {\n",
    "    'PRCP_1': np.mean,\n",
    "    'TAVG_1': np.mean,\n",
    "    'TMAX_1': np.mean,\n",
    "    'TMIN_1': np.mean,\n",
    "    'AWND_1': np.mean\n",
    "}\n",
    "grouped = ws1.groupby(['stationid']).agg(f) #finding mean for FIllna\n",
    "merged = ws1.merge(grouped, on='stationid', suffixes=('_ws1', '_grouped'))\n",
    "# Fill the null values in the merged dataset with the values from 'grouped'\n",
    "merged['PRCP_1_ws1'].fillna(merged['PRCP_1_grouped'], inplace=True)\n",
    "merged['TAVG_1_ws1'].fillna(merged['TAVG_1_grouped'], inplace=True)\n",
    "merged['TMAX_1_ws1'].fillna(merged['TMAX_1_grouped'], inplace=True)\n",
    "merged['TMIN_1_ws1'].fillna(merged['TMIN_1_grouped'], inplace=True)\n",
    "merged['AWND_1_ws1'].fillna(merged['AWND_1_grouped'], inplace=True)\n",
    "\n",
    "# Drop the columns with '_grouped' suffix\n",
    "merged.drop(['PRCP_1_grouped', 'TAVG_1_grouped', 'TMAX_1_grouped', 'TMIN_1_grouped', 'AWND_1_grouped'], axis=1, inplace=True)\n",
    "DF=merged.rename(columns={'PRCP_1_ws1':'PRCP',\n",
    "                       'TAVG_1_ws1':'TAVG',\n",
    "                       'TMAX_1_ws1':'TMAX',\n",
    "                       'TMIN_1_ws1':'TMIN',\n",
    "                       'AWND_1_ws1':'AWND',})\n",
    "DF.drop(['DATE_1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv(\"Data/Temp/FULL_nearest_weather_data_v4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance to nearest water and  campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all=gpd.GeoDataFrame(df_all, geometry=gpd.points_from_xy(df_all.Longitude, df_all.Latitude), crs='EPSG:4326')\n",
    "# gdf_all.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "\n",
    "# get water body data using OpenStreetMap\n",
    "place_name = \"Texas\"\n",
    "tags = {\"natural\": \"water\"}\n",
    "water = ox.geometries_from_place(place_name, tags)\n",
    "water_geometry = water['geometry'].unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water.to_crs(epsg=2277, inplace=True)\n",
    "gdf_all.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "# assume your data is in GeoDataFrames called `gdf_all` and `water`\n",
    "# extract the geometry of the water bodies\n",
    "water_geometry = water['geometry'].unary_union\n",
    "\n",
    "# define a function to calculate the minimum distance between a point and the water bodies\n",
    "def min_distance_to_water(point, water_geometry):\n",
    "    return point.distance(water_geometry)\n",
    "\n",
    "# calculate the distance for each point\n",
    "gdf_all['proximity_water'] = gdf_all.geometry.apply(min_distance_to_water, water_geometry=water_geometry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'water' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcontextily\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mctx\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Find the nearest water body to the station\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m distances \u001b[39m=\u001b[39m water[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mdistance(gdf_all\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]))\n\u001b[0;32m      9\u001b[0m nearest_water \u001b[39m=\u001b[39m distances\u001b[39m.\u001b[39midxmin()\n\u001b[0;32m     10\u001b[0m nearest_water_geom \u001b[39m=\u001b[39m water\u001b[39m.\u001b[39mloc[nearest_water]\u001b[39m.\u001b[39mgeometry\n",
      "\u001b[1;31mNameError\u001b[0m: name 'water' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "#VISUALIZE\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString\n",
    "import contextily as ctx\n",
    "\n",
    "# Find the nearest water body to the station\n",
    "distances = water['geometry'].apply(lambda x: x.distance(gdf_all.geometry.iloc[0]))\n",
    "nearest_water = distances.idxmin()\n",
    "nearest_water_geom = water.loc[nearest_water].geometry\n",
    "\n",
    "station_point = gdf_all.geometry.iloc[0]\n",
    "\n",
    "if isinstance(nearest_water_geom, (Polygon, MultiPolygon)):\n",
    "    nearest_water_geom = nearest_water_geom.boundary\n",
    "\n",
    "# Calculate the nearest point on the water body to the station\n",
    "nearest_point = nearest_water_geom.interpolate(nearest_water_geom.project(station_point))\n",
    "\n",
    "# Create a LineString connecting the station and the nearest point on the water body\n",
    "line = LineString([station_point, nearest_point])\n",
    "\n",
    "# Create a GeoDataFrame for the line\n",
    "line_gdf = gpd.GeoDataFrame(geometry=[line])\n",
    "\n",
    "# Plot the data\n",
    "\n",
    "ax = water.plot(color='blue', alpha=0.5, figsize=(10, 10))\n",
    "#shp_road17_.plot(ax=ax, color=\"grey\")\n",
    "gdf_all.iloc[[0]].plot(ax=ax, color='maroon', markersize=80)\n",
    "line_gdf.plot(ax=ax, color='yellow', linestyle='--', linewidth=2)\n",
    "# ax.set_xlim(2887000,2892000)\n",
    "# ax.set_ylim(9735000,9740000)\n",
    "ctx.add_basemap(ax=ax, crs=gdf_all.crs.to_string(),source=cx.providers.Stamen.TonerLite)\n",
    "ax.set_xlim(3162000,3170000)\n",
    "ax.set_ylim(10094500,10102000)\n",
    "\n",
    "# Create legend\n",
    "legend_elements = [  Patch(facecolor='grey', edgecolor='black', label='Road Network'),    \n",
    "                   Patch(facecolor=\"#800000\", edgecolor='black', label='Count station'),    \n",
    "                   Patch(facecolor='blue', edgecolor='black', label='Water body'),    \n",
    "                   Line2D([0], [0], color='yellow', lw=2, linestyle='--', label='Shortest path')]\n",
    "plt.legend(handles=legend_elements, title='Legend', loc='lower right')\n",
    "\n",
    "ax.set_xticks([]) \n",
    "ax.set_yticks([]) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m shp_road17_\u001b[39m=\u001b[39mgpd\u001b[39m.\u001b[39;49mread_file(\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/#RAW/Data/Txdot_roadway/2017/TxDOT_Roadway_Linework_wAssets.shp\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m shp_road17_\u001b[39m.\u001b[39mto_crs(epsg\u001b[39m=\u001b[39m\u001b[39m2277\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\geopandas\\io\\file.py:259\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m     path_or_bytes \u001b[39m=\u001b[39m filename\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiona\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_fiona(\n\u001b[0;32m    260\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[39m=\u001b[39mbbox, mask\u001b[39m=\u001b[39mmask, rows\u001b[39m=\u001b[39mrows, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    261\u001b[0m     )\n\u001b[0;32m    262\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyogrio\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[0;32m    264\u001b[0m         path_or_bytes, bbox\u001b[39m=\u001b[39mbbox, mask\u001b[39m=\u001b[39mmask, rows\u001b[39m=\u001b[39mrows, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    265\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\geopandas\\io\\file.py:360\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m    357\u001b[0m         [record[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m f_filt], columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 360\u001b[0m     df \u001b[39m=\u001b[39m GeoDataFrame\u001b[39m.\u001b[39;49mfrom_features(\n\u001b[0;32m    361\u001b[0m         f_filt, crs\u001b[39m=\u001b[39;49mcrs, columns\u001b[39m=\u001b[39;49mcolumns \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mgeometry\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m    362\u001b[0m     )\n\u001b[0;32m    363\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m datetime_fields:\n\u001b[0;32m    364\u001b[0m     as_dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[k], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\geopandas\\geodataframe.py:632\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[1;34m(cls, features, crs, columns)\u001b[0m\n\u001b[0;32m    629\u001b[0m rows \u001b[39m=\u001b[39m []\n\u001b[0;32m    630\u001b[0m \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features_lst:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# load geometry\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(feature, \u001b[39m\"\u001b[39;49m\u001b[39m__geo_interface__\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m    633\u001b[0m         feature \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39m__geo_interface__\n\u001b[0;32m    634\u001b[0m     row \u001b[39m=\u001b[39m {\n\u001b[0;32m    635\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m: shape(feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mif\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\fiona\\model.py:354\u001b[0m, in \u001b[0;36mFeature.__geo_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__geo_interface__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mreturn\u001b[39;00m ObjectEncoder()\u001b[39m.\u001b[39;49mdefault(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\fiona\\model.py:381\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    379\u001b[0m         o_dict[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ObjectEncoder()\u001b[39m.\u001b[39mdefault(o\u001b[39m.\u001b[39mgeometry)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m o\u001b[39m.\u001b[39mproperties \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m         o_dict[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ObjectEncoder()\u001b[39m.\u001b[39;49mdefault(o\u001b[39m.\u001b[39;49mproperties)\n\u001b[0;32m    382\u001b[0m     \u001b[39mreturn\u001b[39;00m o_dict\n\u001b[0;32m    383\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\fiona\\model.py:374\u001b[0m, in \u001b[0;36mObjectEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    373\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[1;32m--> 374\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    375\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, Feature):\n\u001b[0;32m    376\u001b[0m         o_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mo)\n",
      "File \u001b[1;32mc:\\Users\\P-Koirala\\AppData\\Local\\miniconda3\\envs\\OSM_miniconda\\lib\\site-packages\\fiona\\model.py:374\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    373\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, (Geometry, Properties)):\n\u001b[1;32m--> 374\u001b[0m         \u001b[39mreturn\u001b[39;00m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m o\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    375\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, Feature):\n\u001b[0;32m    376\u001b[0m         o_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mo)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shp_road17_=gpd.read_file(\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/#RAW/Data/Txdot_roadway/2017/TxDOT_Roadway_Linework_wAssets.shp\")\n",
    "shp_road17_.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all2=gdf_all.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'Texas'\n",
    "amenity = ['university', 'community_college']\n",
    "\n",
    "# Query OpenStreetMap to get the universities in Texas\n",
    "query = f'amenity={amenity} and addr:state={state}'\n",
    "uni = ox.geometries_from_place(state, tags={'amenity': amenity}, which_result=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_geometry = uni['geometry'].unary_union\n",
    "def min_distanc(point, uni_geometry):\n",
    "    return point.distance(uni_geometry)\n",
    "\n",
    "gdf_all2['proximity_uni'] = gdf_all2.geometry.apply(min_distanc, uni_geometry=uni_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all2=gdf_all2.rename(columns={'distance_to_water':'proximity_water'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf_all2.to_csv(\"Data/Temp/FULL_distance_uni_data_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'Texas'\n",
    "amenity = ['school']\n",
    "\n",
    "# Query OpenStreetMap to get the universities in Texas\n",
    "query = f'amenity={amenity} and addr:state={state}'\n",
    "sco = ox.geometries_from_place(state, tags={'amenity': amenity}, which_result=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sco_geometry = sco['geometry'].unary_union\n",
    "def min_distanc(point, sco_geometry):\n",
    "    return point.distance(sco_geometry)\n",
    "\n",
    "gdf_all2['proximity_school'] = gdf_all2.geometry.apply(min_distanc, sco_geometry=sco_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all2.to_csv(\"Data/Temp/FULL_proximity_data_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name=\"Texas\"\n",
    "tags = {'leisure': 'park', 'landuse': 'grass'}\n",
    "parks = ox.geometries_from_place(place_name, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.to_crs(epsg=2277, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_geometry = parks['geometry'].unary_union\n",
    "def min_distanc(point, parks_geometry):\n",
    "    return point.distance(parks_geometry)\n",
    "\n",
    "gdf_all2['proximity_parks'] = gdf_all2.geometry.apply(min_distanc, parks_geometry=parks_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all2.to_csv(\"Data/Temp/trial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_all2.to_csv(\"Data/Temp/FULL_proximity_data_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b53270c4e50afbf33628a12059691a33f1558a8e427dc048f15f23fd121ba86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

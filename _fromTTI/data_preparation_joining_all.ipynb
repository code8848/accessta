{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import osmnx as ox\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations=pd.read_excel(\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/FullSUPIdentifiedData.xlsx\", sheet_name=\"SUPData\", usecols=[\"stationid\",\"sharedpath\", \"Latitude\",'Longitude'])\n",
    "#df_stations=df_stations[df_stations.sharedpath==1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/Temp/\"\n",
    "road=pd.read_csv(url+\"network_density_variables_FULL_condensed_including1516.csv\") \n",
    "demo1mile=pd.read_csv(url+\"FULL_station_and_demographic_1mile.csv\") #also includes the google earth collected data\n",
    "demo05miles=pd.read_csv(url+\"FULL_station_and_demographic_05mile.csv\") #also includes the google earth collected data\n",
    "demo025miles=pd.read_csv(url+\"FULL_station_and_demographic_025mile.csv\") #also includes the google earth collected data\n",
    "#smrt=pd.read_csv(url+\"Full_SmartLocation_data.csv\")\n",
    "route=pd.read_csv(url+\"FULL_Transit_route_density.csv\")\n",
    "stop=pd.read_csv(url+\"FULL_Transit_stops.csv\")\n",
    "intsct=pd.read_csv(url+\"Intersection_count_osm_v2.csv\")\n",
    "lu_replica=pd.read_csv(url+'FULL_replicalanduse_v3.csv')\n",
    "lu_local=pd.read_csv(url+'FULL_localanduse_labeled_assumed.csv')\n",
    "lu_local=lu_local.drop(columns={'stationid.1',\t'stationid.2'\t})\n",
    "proxi=pd.read_csv(url+'FULL_proximity_data_v4.csv')\n",
    "job_access=pd.read_csv(url+'FULL_job_access_ped.csv')\n",
    "job_access_bike=pd.read_csv(url+'FULL_job_access_bike.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_access.rename(columns={\"job_access_15min\":\"job_access_15min_walk\",'job_access_30min':\"job_access_30min_walk\",'job_access_60min':\"job_access_60min_walk\"}, inplace=True)\n",
    "job_access_bike.rename(columns={\"job_access_15min\":\"job_access_15min_bike\",'job_access_30min':\"job_access_30min_bike\",'job_access_60min':\"job_access_60min_bike\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxi.rename(columns={'distance_uni':'proximity_uni'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo1mile=demo1mile.drop(['Latitude', 'Longitude'], axis=1) #its already in df_stations\n",
    "del_cols=['county', 'Latitude', 'Longitude', 'Name', 'Station_Name', 'Same_station_number', 'Direction', 'sharedpath', 'width', 'marking', 'lighting', 'close to freeway', 'benches', 'shading', 'trees', 'one_two_way', 'remark', 'remark_2', 'geometry', 'indexx']\n",
    "demo05miles=demo05miles.drop(del_cols, axis=1)\n",
    "demo025miles=demo025miles.drop(del_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "665\n",
      "665\n",
      "665\n",
      "665\n",
      "681\n",
      "681\n",
      "683\n",
      "683\n",
      "683\n",
      "683\n"
     ]
    }
   ],
   "source": [
    "# merged_file = pd.merge(df_stations, demo, on='stationid')\n",
    "# print(len(merged_file))\n",
    "merged_file = pd.merge(lu_local, lu_replica, on='stationid')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file,demo1mile, on='stationid')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, demo05miles, on='stationid')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, demo025miles, on='stationid')\n",
    "print(len(merged_file))\n",
    "\n",
    "merged_file = pd.merge(merged_file, proxi, on='stationid')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, job_access, on='stationid', how='outer')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, job_access_bike, on='stationid', how='outer')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, intsct, on='stationid', how='outer')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, route, on='stationid', how='outer')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, stop, on='stationid', how='outer')\n",
    "print(len(merged_file))\n",
    "merged_file = pd.merge(merged_file, road, on='stationid', how='outer')\n",
    "print(len(merged_file))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding count_method (permanent or temporary) and other info for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/BPCX data from Phil/\"\n",
    "stationcode=pd.read_csv(url+\"stations as of 202212211541.csv\")\n",
    "stationcode=stationcode[[\"station_id_tmg\", \"surface_type_code\", \"street_lighting_code\",'surface_condition_code', \"count_method_code\"]]\n",
    "stationtype=stationcode.drop_duplicates(subset='station_id_tmg', keep='first')\n",
    "stationtype.rename(columns={\"station_id_tmg\":\"stationid\",\n",
    "\"surface_type_code\":\"surface_type\", \n",
    "\"street_lighting_code\":\"street_lighting\",\n",
    "'surface_condition_code':'surface_condition', \n",
    "\"count_method_code\":\"count_method\" }, \n",
    "inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1237\n",
      "1241\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_file.columns))\n",
    "merged_file = pd.merge(merged_file, stationtype, on='stationid')\n",
    "print(len(merged_file.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file.to_csv(\"Data/Temp/FULL_initial_prepared_data_v13.csv\", index=False)\n",
    "merged_file_SUP=merged_file[merged_file.sharedpath==1]\n",
    "merged_file_SUP.to_csv(\"Data/Temp/FULL_initial_prepared_data_SUP_v13.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formating dataset for modeling (The year in the name of columns is extracted and included in the year column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/Temp/FULL_initial_prepared_data_SUP_v13.csv\")\n",
    "#Here: Format manually between FULL_initial_prepared_data_v7 and FULL_initial_prepared_data_SUP_v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD NEW VARIABLE HERE\n",
    "def rename_columns(df):\n",
    "    new_cols = {col: col.rsplit(\"_\", 1)[0] for col in df.columns}\n",
    "    df = df.rename(columns=new_cols)\n",
    "    return df\n",
    "#The list of columns which which donot have a year at the end of their column names\n",
    "cols=['stationid','sharedpath', 'Same_station_number', 'count_method',\"surface_type\", \"street_lighting\",'surface_condition','width', 'marking', 'lighting', 'close to freeway', 'benches', 'shading', 'trees', 'one_two_way', 'remark', 'remark_2',  \n",
    "      'Bus_025', 'Tram_strcar_lrail_025', 'Bus_05', 'Tram_strcar_lrail_05', 'Bus_1', 'Tram_strcar_lrail_1',  'stops_025mile', 'stops_05mile', 'stops_1mile'\n",
    "      ,'Intsct_05mile','Intsct_025mile','Intsct_1mile',\n",
    "     'proximity_water', 'proximity_uni', 'proximity_school','proximity_parks',\n",
    "        'job_access_15min_walk', 'job_access_30min_walk', 'job_access_60min_walk','job_access_15min_bike', 'job_access_30min_bike', 'job_access_60min_bike',\n",
    "        'lu_replica_res_025mile', 'lu_replica_com_025mile',\n",
    "       'lu_replica_ind_025mile', 'lu_replica_vac_025mile',\n",
    "       'lu_replica_entropy_025mile',  'lu_replica_res_05mile',\n",
    "       'lu_replica_com_05mile', 'lu_replica_ind_05mile',\n",
    "       'lu_replica_vac_05mile', 'lu_replica_entropy_05mile',\n",
    "       'lu_replica_res_1mile', 'lu_replica_com_1mile', 'lu_replica_ind_1mile',\n",
    "       'lu_replica_vac_1mile', 'lu_replica_entropy_1mile',\n",
    "       \n",
    "       'lu_local_res_025mile', 'lu_local_com_025mile',\n",
    "       'lu_local_ind_025mile', 'lu_local_vac_025mile',\n",
    "       'lu_local_entropy_025mile',  'lu_local_res_05mile',\n",
    "       'lu_local_com_05mile', 'lu_local_ind_05mile',\n",
    "       'lu_local_vac_05mile', 'lu_local_entropy_05mile', \n",
    "       'lu_local_res_1mile', 'lu_local_com_1mile', 'lu_local_ind_1mile',\n",
    "       'lu_local_vac_1mile', 'lu_local_entropy_1mile',\n",
    "       \n",
    "       'lu_local_assumed_025mile','lu_local_assumed_05mile','lu_local_assumed_1mile',\n",
    "       ]\n",
    "#2015\n",
    "df_15 = df.filter(regex='15$')\n",
    "df_15=rename_columns(df_15)\n",
    "df_15[cols] = df[cols]\n",
    "df_15['year'] = 2015\n",
    "\n",
    "#2016\n",
    "df_16 = df.filter(regex='16$')\n",
    "df_16=rename_columns(df_16)\n",
    "df_16[cols] = df[cols]\n",
    "df_16['year'] = 2016\n",
    "\n",
    "#2017\n",
    "df_17 = df.filter(regex='17$')\n",
    "df_17=rename_columns(df_17)\n",
    "df_17[cols] = df[cols]\n",
    "df_17['year'] = 2017\n",
    "\n",
    "#2018\n",
    "df_18 = df.filter(regex='18$')\n",
    "df_18=rename_columns(df_18)\n",
    "df_18[cols] = df[cols]\n",
    "df_18['year'] = 2018\n",
    "\n",
    "#2019\n",
    "df_19 = df.filter(regex='19$')\n",
    "df_19=rename_columns(df_19)\n",
    "df_19[cols] = df[cols]\n",
    "df_19['year'] = 2019\n",
    "\n",
    "#2020\n",
    "df_20= df.filter(regex='20$')\n",
    "df_20=rename_columns(df_20)\n",
    "df_20[cols] = df[cols]\n",
    "df_20['year'] = 2020\n",
    "\n",
    "#2021\n",
    "df_21= df.filter(regex='21$')\n",
    "df_21=rename_columns(df_21)\n",
    "df_21[cols] = df[cols]\n",
    "df_21['year'] = 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_15,df_16,df_17,df_18,df_19,df_20,df_21])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new data (dataset with year column already present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/Temp/\"\n",
    "weather=pd.read_csv(url + 'FULL_nearest_weather_data_v4_missingnottreatedbasedonalphabet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df_all.merge(weather, on=['stationid', 'year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=pd.read_csv(\"Data/Temp/raw_data_.csv\")\n",
    "raw_data=raw_data.rename(columns={\"station_id\":\"stationid\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting all the stationid in \"raw_data\" which is not included in df_all and use how=\"outer\" for merging\n",
    "unwanted_stationids=list(set(raw_data.stationid.unique())-set(df_all.stationid.unique()))\n",
    "raw_data2 = raw_data[~raw_data['stationid'].isin(unwanted_stationids)]\n",
    "#Only 2015 to 2021\n",
    "raw_data3=raw_data2[(raw_data2.year>=2015)&(raw_data2.year<2022)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding county information in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/\"\n",
    "county=pd.read_excel(url + 'FullSUPIdentifiedData.xlsx', usecols=['stationid','county','Longitude', 'Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data4=pd.merge(raw_data3, county, on=['stationid'], how='left')\n",
    "DF2 = pd.merge(raw_data4, df_all, on=['stationid', 'year'], how='left')\n",
    "DF3=DF2[~DF2.TotPop_1mile.isna()] #This will exclude all data points which doesnot have ACS data (i.e which might be outside of county boundary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating annual daily traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3[\"ADT_025mile\"] = DF3[\"ADT_CUR_UI_025mile\"] + DF3[\"ADT_CUR_UA_025mile\"] + DF3[\"ADT_CUR_UC_025mile\"] + DF3[\"ADT_CUR_UL_025mile\"] +DF3[\"ADT_CUR_RI_025mile\"] + DF3[\"ADT_CUR_RA_025mile\"] + DF3[\"ADT_CUR_RC_025mile\"] + DF3[\"ADT_CUR_RL_025mile\"]\n",
    "DF3[\"ADT_05mile\"] = DF3[\"ADT_CUR_UI_05mile\"] + DF3[\"ADT_CUR_UA_05mile\"] + DF3[\"ADT_CUR_UC_05mile\"] + DF3[\"ADT_CUR_UL_05mile\"]+DF3[\"ADT_CUR_RI_05mile\"] + DF3[\"ADT_CUR_RA_05mile\"] + DF3[\"ADT_CUR_RC_05mile\"] + DF3[\"ADT_CUR_RL_05mile\"]\n",
    "DF3[\"ADT_1mile\"] = DF3[\"ADT_CUR_UI_1mile\"] + DF3[\"ADT_CUR_UA_1mile\"] + DF3[\"ADT_CUR_UC_1mile\"] + DF3[\"ADT_CUR_UL_1mile\"]+DF3[\"ADT_CUR_RI_1mile\"] + DF3[\"ADT_CUR_RA_1mile\"] + DF3[\"ADT_CUR_RC_1mile\"] + DF3[\"ADT_CUR_RL_1mile\"]\n",
    "\n",
    "# Delete the old columns\n",
    "DF3 = DF3.drop(columns=[\"ADT_CUR_UI_025mile\", \"ADT_CUR_UA_025mile\", \"ADT_CUR_UC_025mile\", \"ADT_CUR_UL_025mile\",\n",
    "                     \"ADT_CUR_UI_05mile\", \"ADT_CUR_UA_05mile\", \"ADT_CUR_UC_05mile\", \"ADT_CUR_UL_05mile\",\n",
    "                     \"ADT_CUR_UI_1mile\", \"ADT_CUR_UA_1mile\", \"ADT_CUR_UC_1mile\", \"ADT_CUR_UL_1mile\",\n",
    "                     \"ADT_CUR_RI_025mile\",\"ADT_CUR_RI_05mile\",\"ADT_CUR_RI_1mile\",\n",
    "                     \"ADT_CUR_RA_025mile\",\"ADT_CUR_RA_05mile\",\"ADT_CUR_RA_1mile\",\n",
    "                     \"ADT_CUR_RC_025mile\",\"ADT_CUR_RC_05mile\",\"ADT_CUR_RC_1mile\",\n",
    "                     \"ADT_CUR_RL_025mile\",\"ADT_CUR_RL_05mile\",\"ADT_CUR_RL_1mile\"\n",
    "])\n",
    "\n",
    "#Previous years ADT\n",
    "DF3[\"ADT_previous_year_025mile\"] = DF3[\"ADT_previous_year_UI_025mile\"] + DF3[\"ADT_previous_year_UA_025mile\"] + DF3[\"ADT_previous_year_UC_025mile\"] + DF3[\"ADT_previous_year_UL_025mile\"] +DF3[\"ADT_previous_year_RI_025mile\"] + DF3[\"ADT_previous_year_RA_025mile\"] + DF3[\"ADT_previous_year_RC_025mile\"] + DF3[\"ADT_previous_year_RL_025mile\"]\n",
    "DF3[\"ADT_previous_year_05mile\"] = DF3[\"ADT_previous_year_UI_05mile\"] + DF3[\"ADT_previous_year_UA_05mile\"] + DF3[\"ADT_previous_year_UC_05mile\"] + DF3[\"ADT_previous_year_UL_05mile\"]+DF3[\"ADT_previous_year_RI_05mile\"] + DF3[\"ADT_previous_year_RA_05mile\"] + DF3[\"ADT_previous_year_RC_05mile\"] + DF3[\"ADT_previous_year_RL_05mile\"]\n",
    "DF3[\"ADT_previous_year_1mile\"] = DF3[\"ADT_previous_year_UI_1mile\"] + DF3[\"ADT_previous_year_UA_1mile\"] + DF3[\"ADT_previous_year_UC_1mile\"] + DF3[\"ADT_previous_year_UL_1mile\"]+DF3[\"ADT_previous_year_RI_1mile\"] + DF3[\"ADT_previous_year_RA_1mile\"] + DF3[\"ADT_previous_year_RC_1mile\"] + DF3[\"ADT_previous_year_RL_1mile\"]\n",
    "\n",
    "#Delete the old columns\n",
    "DF3 = DF3.drop(columns=[\"ADT_previous_year_UI_025mile\", \"ADT_previous_year_UA_025mile\", \"ADT_previous_year_UC_025mile\", \"ADT_previous_year_UL_025mile\",\n",
    "\"ADT_previous_year_UI_05mile\", \"ADT_previous_year_UA_05mile\", \"ADT_previous_year_UC_05mile\", \"ADT_previous_year_UL_05mile\",\n",
    "\"ADT_previous_year_UI_1mile\", \"ADT_previous_year_UA_1mile\", \"ADT_previous_year_UC_1mile\", \"ADT_previous_year_UL_1mile\",\n",
    "\"ADT_previous_year_RI_025mile\",\"ADT_previous_year_RI_05mile\",\"ADT_previous_year_RI_1mile\",\n",
    "\"ADT_previous_year_RA_025mile\",\"ADT_previous_year_RA_05mile\",\"ADT_previous_year_RA_1mile\",\n",
    "\"ADT_previous_year_RC_025mile\",\"ADT_previous_year_RC_05mile\",\"ADT_previous_year_RC_1mile\",\n",
    "\"ADT_previous_year_RL_025mile\",\"ADT_previous_year_RL_05mile\",\"ADT_previous_year_RL_1mile\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF3.to_excel(\"Data/Temp/FULL_prepared_data_SUP_v13.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMpeak AND PMpeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregading direction and calculting ampeak and pmpeak\n",
    "peakdf=DF3.groupby(['stationid', 'year', 'Mode', 'hour'], as_index=False)['count'].sum()\n",
    "def peak(x):\n",
    "    am_peak = x[(x.hour == 10) | (x.hour == 9)]['count'].sum()\n",
    "    pm_peak = x[(x.hour == 17) | (x.hour == 18)]['count'].sum()\n",
    "    daily_count= x['count'].sum()\n",
    "    return pd.Series({'ampeak': am_peak, 'pmpeak': pm_peak, 'daily_count':daily_count})\n",
    "peakdf2=peakdf.groupby(['stationid', 'year', 'Mode'], as_index=False).apply(peak)\n",
    "#Calculating daiuly count\n",
    "data_to_add_with_peakdf=DF3.groupby(['stationid', 'year', 'Mode'], as_index=False).first()\n",
    "data_to_add_with_peakdf=data_to_add_with_peakdf.drop(['flowid_txdot','hour','count','direction'], axis=1)\n",
    "#merging both dataset\n",
    "peakdf3=peakdf2.merge(data_to_add_with_peakdf, on=['stationid','year','Mode'], how='right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing weather data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(peakdf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be treated by fillna(0): all roadway inventory data columns and job access, intersection ..\n",
    "#To be treated: weather, ADT\n",
    "missingcols=['surface_type','street_lighting','surface_condition', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean values of the respective county\n",
    "for column in ['TAVG', 'TMAX', 'TMIN', 'AWND']:\n",
    "    peakdf3[column] = peakdf3.groupby('county')[column].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Some values are still missing after location-based treatment, for those, the average of the whole Texas is assigned\n",
    "mean_values = peakdf3[['TAVG', 'TMAX', 'TMIN', 'AWND']].mean()\n",
    "peakdf3[['TAVG', 'TMAX', 'TMIN', 'AWND']] = peakdf3[['TAVG', 'TMAX', 'TMIN', 'AWND']].fillna(mean_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationid</th>\n",
       "      <th>year</th>\n",
       "      <th>Mode</th>\n",
       "      <th>ampeak</th>\n",
       "      <th>pmpeak</th>\n",
       "      <th>daily_count</th>\n",
       "      <th>county</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>TotPop_1mile</th>\n",
       "      <th>...</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>AWND</th>\n",
       "      <th>ADT_025mile</th>\n",
       "      <th>ADT_05mile</th>\n",
       "      <th>ADT_1mile</th>\n",
       "      <th>ADT_previous_year_025mile</th>\n",
       "      <th>ADT_previous_year_05mile</th>\n",
       "      <th>ADT_previous_year_1mile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bic</td>\n",
       "      <td>6.588235</td>\n",
       "      <td>6.359477</td>\n",
       "      <td>38.451007</td>\n",
       "      <td>Collin</td>\n",
       "      <td>33.119987</td>\n",
       "      <td>-96.666206</td>\n",
       "      <td>6385.01131</td>\n",
       "      <td>...</td>\n",
       "      <td>66.3</td>\n",
       "      <td>77.2</td>\n",
       "      <td>55.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL0001</td>\n",
       "      <td>2017</td>\n",
       "      <td>Ped</td>\n",
       "      <td>29.660870</td>\n",
       "      <td>18.286957</td>\n",
       "      <td>143.886957</td>\n",
       "      <td>Collin</td>\n",
       "      <td>33.119987</td>\n",
       "      <td>-96.666206</td>\n",
       "      <td>6385.01131</td>\n",
       "      <td>...</td>\n",
       "      <td>66.3</td>\n",
       "      <td>77.2</td>\n",
       "      <td>55.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL0001</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bic</td>\n",
       "      <td>5.643836</td>\n",
       "      <td>4.534247</td>\n",
       "      <td>29.701377</td>\n",
       "      <td>Collin</td>\n",
       "      <td>33.119987</td>\n",
       "      <td>-96.666206</td>\n",
       "      <td>6429.97944</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL0001</td>\n",
       "      <td>2018</td>\n",
       "      <td>Ped</td>\n",
       "      <td>24.649315</td>\n",
       "      <td>18.232877</td>\n",
       "      <td>134.074101</td>\n",
       "      <td>Collin</td>\n",
       "      <td>33.119987</td>\n",
       "      <td>-96.666206</td>\n",
       "      <td>6429.97944</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL0001</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bic</td>\n",
       "      <td>5.505051</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>29.629630</td>\n",
       "      <td>Collin</td>\n",
       "      <td>33.119987</td>\n",
       "      <td>-96.666206</td>\n",
       "      <td>6499.48103</td>\n",
       "      <td>...</td>\n",
       "      <td>64.8</td>\n",
       "      <td>75.4</td>\n",
       "      <td>54.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>WF0001</td>\n",
       "      <td>2018</td>\n",
       "      <td>All</td>\n",
       "      <td>10.636364</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>83.909091</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>33.868206</td>\n",
       "      <td>-98.509804</td>\n",
       "      <td>23571.18323</td>\n",
       "      <td>...</td>\n",
       "      <td>63.8</td>\n",
       "      <td>76.2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>WF0002</td>\n",
       "      <td>2018</td>\n",
       "      <td>All</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>21.454545</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>33.921909</td>\n",
       "      <td>-98.474602</td>\n",
       "      <td>4555.79132</td>\n",
       "      <td>...</td>\n",
       "      <td>63.8</td>\n",
       "      <td>76.2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>WF0003</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bic</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>40.571429</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>33.913994</td>\n",
       "      <td>-98.505325</td>\n",
       "      <td>14570.61666</td>\n",
       "      <td>...</td>\n",
       "      <td>63.8</td>\n",
       "      <td>76.2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>WF0005</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bic</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.598485</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>33.958132</td>\n",
       "      <td>-98.603239</td>\n",
       "      <td>2346.31169</td>\n",
       "      <td>...</td>\n",
       "      <td>63.8</td>\n",
       "      <td>76.2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>WF0006</td>\n",
       "      <td>2018</td>\n",
       "      <td>Bic</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>2.454545</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>33.950585</td>\n",
       "      <td>-98.506615</td>\n",
       "      <td>2834.03303</td>\n",
       "      <td>...</td>\n",
       "      <td>63.8</td>\n",
       "      <td>76.2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290 rows Ã— 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stationid  year Mode     ampeak     pmpeak  daily_count   county  \\\n",
       "0       AL0001  2017  Bic   6.588235   6.359477    38.451007   Collin   \n",
       "1       AL0001  2017  Ped  29.660870  18.286957   143.886957   Collin   \n",
       "2       AL0001  2018  Bic   5.643836   4.534247    29.701377   Collin   \n",
       "3       AL0001  2018  Ped  24.649315  18.232877   134.074101   Collin   \n",
       "4       AL0001  2019  Bic   5.505051   4.636364    29.629630   Collin   \n",
       "...        ...   ...  ...        ...        ...          ...      ...   \n",
       "1285    WF0001  2018  All  10.636364   5.000000    83.909091  Wichita   \n",
       "1286    WF0002  2018  All   4.090909   2.272727    21.454545  Wichita   \n",
       "1287    WF0003  2018  Bic   8.714286   5.857143    40.571429  Wichita   \n",
       "1288    WF0005  2018  Bic   0.272727   0.181818     1.598485  Wichita   \n",
       "1289    WF0006  2018  Bic   0.454545   0.272727     2.454545  Wichita   \n",
       "\n",
       "       Latitude  Longitude  TotPop_1mile  ...  TAVG  TMAX  TMIN  AWND  \\\n",
       "0     33.119987 -96.666206    6385.01131  ...  66.3  77.2  55.5   8.9   \n",
       "1     33.119987 -96.666206    6385.01131  ...  66.3  77.2  55.5   8.9   \n",
       "2     33.119987 -96.666206    6429.97944  ...  65.0  75.5  54.6   8.9   \n",
       "3     33.119987 -96.666206    6429.97944  ...  65.0  75.5  54.6   8.9   \n",
       "4     33.119987 -96.666206    6499.48103  ...  64.8  75.4  54.2   8.9   \n",
       "...         ...        ...           ...  ...   ...   ...   ...   ...   \n",
       "1285  33.868206 -98.509804   23571.18323  ...  63.8  76.2  51.4  11.2   \n",
       "1286  33.921909 -98.474602    4555.79132  ...  63.8  76.2  51.4  11.2   \n",
       "1287  33.913994 -98.505325   14570.61666  ...  63.8  76.2  51.4  11.2   \n",
       "1288  33.958132 -98.603239    2346.31169  ...  63.8  76.2  51.4  11.2   \n",
       "1289  33.950585 -98.506615    2834.03303  ...  63.8  76.2  51.4  11.2   \n",
       "\n",
       "      ADT_025mile  ADT_05mile  ADT_1mile  ADT_previous_year_025mile  \\\n",
       "0             NaN         NaN        NaN                        NaN   \n",
       "1             NaN         NaN        NaN                        NaN   \n",
       "2             NaN         NaN        NaN                        NaN   \n",
       "3             NaN         NaN        NaN                        NaN   \n",
       "4             NaN         NaN        NaN                        NaN   \n",
       "...           ...         ...        ...                        ...   \n",
       "1285          NaN         NaN        NaN                        NaN   \n",
       "1286          NaN         NaN        NaN                        NaN   \n",
       "1287          NaN         NaN        NaN                        NaN   \n",
       "1288          NaN         NaN        NaN                        NaN   \n",
       "1289          NaN         NaN        NaN                        NaN   \n",
       "\n",
       "      ADT_previous_year_05mile  ADT_previous_year_1mile  \n",
       "0                          NaN                      NaN  \n",
       "1                          NaN                      NaN  \n",
       "2                          NaN                      NaN  \n",
       "3                          NaN                      NaN  \n",
       "4                          NaN                      NaN  \n",
       "...                        ...                      ...  \n",
       "1285                       NaN                      NaN  \n",
       "1286                       NaN                      NaN  \n",
       "1287                       NaN                      NaN  \n",
       "1288                       NaN                      NaN  \n",
       "1289                       NaN                      NaN  \n",
       "\n",
       "[1290 rows x 209 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peakdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakdf3=peakdf3.groupby(['stationid','year','Mode'], as_index=False).agg('first') #There were a lot of dublicates in the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/BPCX data from Phil/\"\n",
    "cityinfo=pd.read_csv(url+\"_SELECT_s_station_id_tmg_s_flowid_txdot_s_eco_id_s_eco_name_s_se Readable as of 202212211543.csv\")\n",
    "cityinfo=cityinfo[['station_id_tmg','city_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakdf4=pd.merge(peakdf3, cityinfo, right_on='station_id_tmg', left_on='stationid', how=\"left\")\n",
    "peakdf4=peakdf4.drop([\"station_id_tmg\"], axis=1)\n",
    "peakdf4=peakdf4.groupby(['stationid','year','Mode'], as_index=False).agg('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding phils data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "url='C:/Users/P-Koirala/OneDrive - Texas A&M Transportation Institute/Desktop/Data/SUP/Data/BPCX data from Phil/'\n",
    "ADT_from_phil=pd.read_csv(url+\"ADT_Counts_202304261556.csv\")\n",
    "ADT_from_phil=ADT_from_phil[ADT_from_phil.cmpl1_incmpl0==1] ###################### Filter. The column name suggest complete and incomplete. This might indicate the data collection part.\n",
    "ADT_from_phil['stationid']=ADT_from_phil.flowid_txdot.str[:6]\n",
    "ADT_from_phil['Mode']=ADT_from_phil.flowid_txdot.str[-3:]\n",
    "ADT_from_phil.Mode.replace({\"BIc\":'Bic'}, inplace=True)\n",
    "\n",
    "AADT_from_phil=pd.read_csv(url+\"AADT_202304261555.csv\")\n",
    "AADT_from_phil=AADT_from_phil[AADT_from_phil.cmpl1_incmpl0==1] ###################### Filter. The column name suggest complete and incomplete. This might indicate the data collection part.\n",
    "AADT_from_phil['stationid']=AADT_from_phil.flowid_txdot.str[:6]\n",
    "AADT_from_phil['Mode']=AADT_from_phil.flowid_txdot.str[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing dublicate\n",
    "ADT_from_phil = ADT_from_phil.drop_duplicates(subset=['stationid', 'Mode', 'year'], keep='first')\n",
    "AADT_from_phil = AADT_from_phil.drop_duplicates(subset=['stationid', 'Mode', 'year'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with ADT phil\n",
    "peakdf5 = pd.merge(peakdf4, ADT_from_phil[['stationid', 'Mode', 'year', 'ADT']], \n",
    "                   on=['stationid', 'Mode', 'year'], \n",
    "                   how='left')\n",
    "peakdf5.rename(columns={'ADT': 'ADT_phil'}, inplace=True)# rename the ADT column\n",
    "\n",
    "# merge with AADT phil\n",
    "peakdf5 = pd.merge(peakdf5, AADT_from_phil[['stationid', 'Mode', 'year', 'AADT']], \n",
    "                   on=['stationid', 'Mode', 'year'], \n",
    "                   how='left')\n",
    "peakdf5.rename(columns={'AADT': 'AADT_phil'}, inplace=True)# rename the AADT column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakdf5.to_excel(\"Data/Temp/FULL_prepared_data_ampm_SUP_v13.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique station for each year\n",
    "table=[]\n",
    "years=[2015,2016,2017,2018,2019,2020,2021]\n",
    "for yearz in years:\n",
    "    num=len(peakdf4[peakdf4.year==yearz].stationid.unique())\n",
    "    dic={'year':yearz, \"unique_statios\":num}\n",
    "    table.append(dic)\n",
    "Table=pd.DataFrame(table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationid</th>\n",
       "      <th>year</th>\n",
       "      <th>Mode</th>\n",
       "      <th>hour</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>AU0004</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ped</td>\n",
       "      <td>9</td>\n",
       "      <td>6.367442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>AU0004</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ped</td>\n",
       "      <td>10</td>\n",
       "      <td>8.544186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stationid  year Mode  hour     count\n",
       "513    AU0004  2015  Ped     9  6.367442\n",
       "514    AU0004  2015  Ped    10  8.544186"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition=(peakdf.stationid=='AU0004') & (peakdf.year==2015) & (peakdf.Mode=='Ped') & (peakdf.hour>8) & (peakdf.hour<11)\n",
    "peakdf[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.911627906976744"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peakdf[condition]['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationid</th>\n",
       "      <th>year</th>\n",
       "      <th>Mode</th>\n",
       "      <th>ampeak</th>\n",
       "      <th>pmpeak</th>\n",
       "      <th>daily_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AU0004</td>\n",
       "      <td>2015</td>\n",
       "      <td>Ped</td>\n",
       "      <td>14.911628</td>\n",
       "      <td>9.046512</td>\n",
       "      <td>115.84186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stationid  year Mode     ampeak    pmpeak  daily_count\n",
       "21    AU0004  2015  Ped  14.911628  9.046512    115.84186"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition2=(peakdf2.stationid=='AU0004') & (peakdf2.year==2015) & (peakdf2.Mode=='Ped')\n",
    "peakdf2[condition2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b53270c4e50afbf33628a12059691a33f1558a8e427dc048f15f23fd121ba86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
